{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook is for trying out what research I have read and my ideas in this [Notion](https://www.notion.so/Model-evaluation-170d3cfe027d80889de3cfbb35b531a4).\n",
    "\n",
    "I played around with a Mistral Large model to build a mathematics chatbot. It is simple and I prompt engineered it. I might change the model to a smaller and cheaper one, but I still want to use a model that is considerd good enough. My plan is to use three small open source models to evaluate the mahtematics model. I'll also use different models for the mathematics chatbot and for the evaluation models to get realible results.\n",
    "\n",
    "I'll use this [dataset](https://github.com/google-deepmind/mathematics_dataset?tab=readme-ov-file) as a test data set. I'll select 50 mathematics questiosn from the dataset. Then I'll ask the mathematicsbot the same questions. \n",
    "Then I'll let: \n",
    "- First a Mistral Large model compare the answers. Same model as in the mathematicsbot but different prompt engineering. \n",
    "    - This is not a good way to evaluate models, but I wish to try it. Espeacilly when it is only 50 questions it is manageble for me to compare the answers.\n",
    "- Then I'll let three smaller open-source models compare the answers.\n",
    "- After that I'll add a fourth model to compare the answers of the three open-open source model to give a final evaluation about the mathematics chat bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mistralai in ./venv/lib/python3.11/site-packages (1.2.6)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in ./venv/lib/python3.11/site-packages (from mistralai) (0.2.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in ./venv/lib/python3.11/site-packages (from mistralai) (0.27.2)\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in ./venv/lib/python3.11/site-packages (from mistralai) (1.0.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in ./venv/lib/python3.11/site-packages (from mistralai) (2.10.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in ./venv/lib/python3.11/site-packages (from mistralai) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-inspect<0.10.0,>=0.9.0 in ./venv/lib/python3.11/site-packages (from mistralai) (0.9.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (4.8.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (1.0.7)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (3.10)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->mistralai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.0->mistralai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.0->mistralai) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.0->mistralai) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.8.2->mistralai) (1.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.11/site-packages (from typing-inspect<0.10.0,>=0.9.0->mistralai) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.11/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: mathematics_dataset in ./venv/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: absl-py>=0.1.0 in ./venv/lib/python3.11/site-packages (from mathematics_dataset) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.10 in ./venv/lib/python3.11/site-packages (from mathematics_dataset) (1.24.3)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.11/site-packages (from mathematics_dataset) (1.17.0)\n",
      "Requirement already satisfied: sympy>=1.2 in ./venv/lib/python3.11/site-packages (from mathematics_dataset) (1.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.11/site-packages (from sympy>=1.2->mathematics_dataset) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pip in ./venv/lib/python3.11/site-packages (23.1.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement install (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for install\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy==1.24.3 in ./venv/lib/python3.11/site-packages (1.24.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install mistralai\n",
    "!pip3 install python-dotenv\n",
    "!pip3 install mathematics_dataset\n",
    "!pip3 install pip install sympy==1.6\n",
    "!pip3 install numpy==1.24.3\n",
    "!pip3 install transformers==4.48.0\n",
    "!pip3 install tiktoken==0.8.0\n",
    "!pip3 install protobuf==5.29.3\n",
    "!pip3 install sentencepiece==0.2.0\n",
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've used the following prompt for the Mistral Large 2.1 model\n",
    "\"Your task is to help solve math problems. Generate three answers that helps solving the problem but doesn't give the solution. When generating the 4th answer to the problem you can give the solution. When you don't know the answer say that you don't know the answer. Write the mathematical part of the answer in latex.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. To compute the eigenvalues of the matrix $A$, you need to solve the characteristic equation $\\det(A - \\lambda I) = 0$, where $I$ is the identity matrix. This involves finding the roots of the characteristic polynomial.\n",
      "\n",
      "2. For each eigenvalue $\\lambda$ found in step 1, solve the equation $(A - \\lambda I)v = 0$ to find the corresponding eigenvectors $v$. This involves solving a homogeneous system of linear equations for each eigenvalue.\n",
      "\n",
      "3. To verify that for each eigenpair $(\\lambda, v)$, the equation $A * v = \\lambda * v$ holds, substitute the eigenvalue $\\lambda$ and the corresponding eigenvector $v$ into the equation and check if the left-hand side equals the right-hand side.\n",
      "\n",
      "4. To diagonalize the matrix $A$, we need to form the matrix $P$ whose columns are the eigenvectors of $A$, and the diagonal matrix $D$ whose diagonal elements are the eigenvalues of $A$. Then, we can check if $A = P * D * P^{-1}$.\n",
      "\n",
      "   For the given matrix $A = \\begin{bmatrix}\n",
      "   4 & 1 & -2 \\\\\n",
      "   1 & 3 & 0 \\\\\n",
      "   -2 & 0 & 2\n",
      "   \\end{bmatrix}$,\n",
      "\n",
      "   The characteristic polynomial is given by $\\det(A - \\lambda I) = \\det\\begin{bmatrix}\n",
      "   4-\\lambda & 1 & -2 \\\\\n",
      "   1 & 3-\\lambda & 0 \\\\\n",
      "   -2 & 0 & 2-\\lambda\n",
      "   \\end{bmatrix} = 0$.\n",
      "\n",
      "   Solving this, we get the eigenvalues $\\lambda_1 = 1$, $\\lambda_2 = 2$, and $\\lambda_3 = 6$.\n",
      "\n",
      "   For $\\lambda_1 = 1$, solving $(A - I)v = 0$ gives the eigenvector $v_1 = \\begin{bmatrix}\n",
      "   1 \\\\\n",
      "   -2 \\\\\n",
      "   1\n",
      "   \\end{bmatrix}$.\n",
      "\n",
      "   For $\\lambda_2 = 2$, solving $(A - 2I)v = 0$ gives the eigenvector $v_2 = \\begin{bmatrix}\n",
      "   0 \\\\\n",
      "   1 \\\\\n",
      "   0\n",
      "   \\end{bmatrix}$.\n",
      "\n",
      "   For $\\lambda_3 = 6$, solving $(A - 6I)v = 0$ gives the eigenvector $v_3 = \\begin{bmatrix}\n",
      "   1 \\\\\n",
      "   2 \\\\\n",
      "   -2\n",
      "   \\end{bmatrix}$.\n",
      "\n",
      "   Thus, the matrix $P = \\begin{bmatrix}\n",
      "   1 & 0 & 1 \\\\\n",
      "   -2 & 1 & 2 \\\\\n",
      "   1 & 0 & -2\n",
      "   \\end{bmatrix}$ and $D = \\begin{bmatrix}\n",
      "   1 & 0 & 0 \\\\\n",
      "   0 & 2 & 0 \\\\\n",
      "   0 & 0 & 6\n",
      "   \\end{bmatrix}$.\n",
      "\n",
      "   You can verify that $A = P * D * P^{-1}$.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "agent_id = os.environ[\"MISTRAL_AGENT_ID\"]\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "chat_response = client.agents.complete(\n",
    "    agent_id= agent_id,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"Given the matrix:\n",
    "                            A = [\n",
    "                                [4, 1, -2],\n",
    "                                [1, 3,  0],\n",
    "                                [-2, 0, 2]\n",
    "                            ]\n",
    "\n",
    "                            Tasks:\n",
    "                            1. Compute the eigenvalues of A.\n",
    "                            2. Compute the eigenvectors of A for each eigenvalue.\n",
    "                            3. Verify that for each eigenpair (λ, v), the equation A * v = λ * v holds.\n",
    "                            4. If possible, diagonalize A by finding matrices P (eigenvectors) and D (diagonal matrix of eigenvalues) such that A = P * D * P⁻¹.\n",
    "                            \"\"\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used the [mathematics_dataset](https://github.com/google-deepmind/mathematics_dataset) from Google DeepMind that will work as a test set. The main issue is that I don't know if the Mistral Large model that is used for the mathematics model have been trained on this data. There is a great chans for that. \n",
    "\n",
    "Never the less, I made a json file called questions_and_answers of the [mathematics_dataset](https://github.com/google-deepmind/mathematics_dataset) so that I can easily separet the questions from the answers. Ideally I would run all the questions through the mathematics model, but due to budget questions that won't be possible. I'll choose around 50 questions from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to questions_and_answers.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def clean_ansi(text):\n",
    "    \"\"\"Remove ANSI color codes from text\"\"\"\n",
    "    ansi_pattern = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\\\[[0-?]*[ -/]*[@-~])')\n",
    "    return ansi_pattern.sub('', text)\n",
    "\n",
    "def process_qa_data(raw_text, output_file=\"questions_and_answers.json\"):\n",
    "    \"\"\"Process raw text into question-answer pairs and save to JSON\"\"\"\n",
    "    qa_pairs = []\n",
    "    \n",
    "    # Split into lines and process each line\n",
    "    lines = raw_text.split('\\n') if isinstance(raw_text, str) else raw_text\n",
    "    \n",
    "    current_section = None\n",
    "    current_question = []\n",
    "    previous_answer = None\n",
    "    \n",
    "    for line in lines:\n",
    "        # Skip empty lines\n",
    "        if not line.strip():\n",
    "            continue\n",
    "            \n",
    "        # Check if this is a section header\n",
    "        if line.startswith('\\u001b[1m') and '\\u001b[92m' not in line:\n",
    "            current_section = clean_ansi(line.strip())\n",
    "            current_question = []\n",
    "            previous_answer = None\n",
    "            continue\n",
    "            \n",
    "        # Skip log messages\n",
    "        if line.startswith('W') and ']' in line:\n",
    "            continue\n",
    "        \n",
    "        # If line contains an answer (marked by green color code)\n",
    "        if '\\u001b[92m' in line:\n",
    "            parts = line.split('\\u001b[92m')\n",
    "            \n",
    "            # Get the question part (if any)\n",
    "            question_part = parts[0].strip()\n",
    "            \n",
    "            # If there's a reset code in the question part, it contains a previous answer\n",
    "            if '\\u001b[0m' in question_part:\n",
    "                q_parts = question_part.split('\\u001b[0m')\n",
    "                if len(q_parts) > 1 and previous_answer is not None:\n",
    "                    # Complete the previous answer\n",
    "                    qa_pairs[-1][\"answer\"] += ' ' + clean_ansi(q_parts[0].strip())\n",
    "                    # Update the question part to exclude the previous answer\n",
    "                    question_part = q_parts[1].strip()\n",
    "            \n",
    "            # Add any new question part to current question\n",
    "            if question_part:\n",
    "                current_question.append(question_part)\n",
    "            \n",
    "            # Get the answer\n",
    "            answer = parts[1].strip()\n",
    "            if '\\u001b[0m' in answer:\n",
    "                answer = answer.split('\\u001b[0m')[0].strip()\n",
    "            \n",
    "            # Combine all question parts\n",
    "            full_question = ' '.join(current_question).strip()\n",
    "            \n",
    "            # Add the new QA pair\n",
    "            if answer:\n",
    "                qa_pairs.append({\n",
    "                    \"section\": clean_ansi(current_section) if current_section else None,\n",
    "                    \"question\": full_question,\n",
    "                    \"answer\": clean_ansi(answer)\n",
    "                })\n",
    "                previous_answer = answer\n",
    "            \n",
    "            # Reset question accumulator\n",
    "            current_question = []\n",
    "        else:\n",
    "            # If line doesn't contain an answer, check if it contains a previous answer completion\n",
    "            if '\\u001b[0m' in line:\n",
    "                parts = line.split('\\u001b[0m')\n",
    "                if previous_answer is not None:\n",
    "                    # Add to previous answer\n",
    "                    qa_pairs[-1][\"answer\"] += ' ' + clean_ansi(parts[0].strip())\n",
    "                    # Add remaining part to current question\n",
    "                    if len(parts) > 1 and parts[1].strip():\n",
    "                        current_question.append(parts[1].strip())\n",
    "            else:\n",
    "                # Regular question part\n",
    "                current_question.append(line.strip())\n",
    "    \n",
    "    # Filter out any entries with empty questions\n",
    "    qa_pairs = [pair for pair in qa_pairs if pair[\"answer\"] and pair[\"question\"]]\n",
    "    \n",
    "    # Save to JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(qa_pairs, f, indent=2)\n",
    "    \n",
    "    print(f\"Output saved to {output_file}\")\n",
    "    return qa_pairs\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the output from mathematics_dataset.generate\n",
    "    output = !python -m mathematics_dataset.generate\n",
    "    \n",
    "    # Process the output\n",
    "    qa_data = process_qa_data(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to clean_qa_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def clean_specific_ansi(text):\n",
    "    \"\"\"Remove specific ANSI codes\"\"\"\n",
    "    if text:\n",
    "        return text.replace('\\u001b[1m', '').replace('\\u001b[0m', '')\n",
    "    return text\n",
    "\n",
    "def clean_json_file(input_file=\"questions_and_answers.json\", output_file=\"clean_qa_data.json\"):\n",
    "    # Read the JSON file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Clean specific ANSI codes from each field\n",
    "    clean_data = []\n",
    "    for item in data:\n",
    "        clean_item = {\n",
    "            \"section\": clean_specific_ansi(item[\"section\"]),\n",
    "            \"question\": clean_specific_ansi(item[\"question\"]),\n",
    "            \"answer\": clean_specific_ansi(item[\"answer\"])\n",
    "        }\n",
    "        clean_data.append(clean_item)\n",
    "    \n",
    "    # Write the cleaned data back to a new JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(clean_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Cleaned data saved to {output_file}\")\n",
    "    return clean_data\n",
    "\n",
    "# Run the cleaning\n",
    "clean_data = clean_json_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the JSON data from the file\n",
    "with open('clean_qa_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Extract only the questions\n",
    "questions = [entry[\"question\"] for entry in data]\n",
    "\n",
    "# Optionally, you can save the questions to a new JSON file\n",
    "with open('questions.json', 'w') as json_file:\n",
    "    json.dump(questions, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try \"google/t5-small-ssm-nq\" cannot classify answers correctly when the Mistral Large model gives the output in the form \"The answer is 4\" and it compares it to only the mathematical answer \"4\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is 2 + 2?', 'expected_answer': '4', 'mistral_answer': 'The answer is 4', 'model_judgment': 'incorrect answers', 'mathematical_correct': False}\n",
      "{'question': 'What is 3 * 3?', 'expected_answer': '9', 'mistral_answer': 'When multiplying, 3 * 3 equals 9', 'model_judgment': 'incorrect answers', 'mathematical_correct': False}\n",
      "{'question': 'What is 10 - 3?', 'expected_answer': '7', 'mistral_answer': 'Subtracting, we get 6', 'model_judgment': 'incorrect answers', 'mathematical_correct': False}\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "from sympy import sympify, Eq, simplify\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "model_name = \"google/t5-small-ssm-nq\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "# Example datasets\n",
    "dataset = [\n",
    "    {\"question\": \"What is 2 + 2?\", \"expected_answer\": \"4\", \"mistral_answer\": \"The answer is 4\"},\n",
    "    {\"question\": \"What is 3 * 3?\", \"expected_answer\": \"9\", \"mistral_answer\": \"When multiplying, 3 * 3 equals 9\"},\n",
    "    {\"question\": \"What is 10 - 3?\", \"expected_answer\": \"7\", \"mistral_answer\": \"Subtracting, we get 6\"}\n",
    "]\n",
    "\n",
    "# Function to validate correctness using the model\n",
    "def validate_correctness(question, mistral_answer, expected_answer):\n",
    "    def extract_math(expr):\n",
    "        \"\"\"\n",
    "        Extract and simplify the mathematical part of an expression.\n",
    "        Returns the simplified math expression or None if parsing fails.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return simplify(sympify(expr))\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # Use T5 to classify the correctness of the Mistral model's output\n",
    "    prompt = (\n",
    "        f\"Evaluate if the given answer is correct:\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Mistral's Answer: {mistral_answer}\\n\"\n",
    "        f\"Expected Answer: {expected_answer}\\n\"\n",
    "        f\"Respond with 'Correct' or 'Incorrect'.\"\n",
    "    )\n",
    "\n",
    "    # Generate T5's judgment\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs.input_ids, max_length=10)\n",
    "    model_judgment = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Also validate mathematically\n",
    "    mistral_expr = extract_math(mistral_answer)\n",
    "    expected_expr = extract_math(expected_answer)\n",
    "    mathematical_correct = mistral_expr == expected_expr\n",
    "\n",
    "    return {\n",
    "        \"model_judgment\": model_judgment,\n",
    "        \"mathematical_correct\": mathematical_correct\n",
    "    }\n",
    "\n",
    "# Evaluate the dataset\n",
    "results = []\n",
    "for item in dataset:\n",
    "    result = validate_correctness(\n",
    "        question=item[\"question\"],\n",
    "        mistral_answer=item[\"mistral_answer\"],\n",
    "        expected_answer=item[\"expected_answer\"]\n",
    "    )\n",
    "    results.append({**item, **result})\n",
    "\n",
    "# Print results\n",
    "for res in results:\n",
    "    print(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
